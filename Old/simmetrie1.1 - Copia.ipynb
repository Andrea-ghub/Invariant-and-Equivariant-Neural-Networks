{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b741526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms.functional import rotate\n",
    "from scipy.linalg import lstsq, null_space\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "442116b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(d): # questa è  rot_mat\n",
    "    mat = np.zeros(d**4).reshape(d**2,d**2)\n",
    "    for j in range(d):\n",
    "        for i in range(d):\n",
    "            k = (i+1)*d-j\n",
    "            h = i+(j)*d+1\n",
    "#             print(h,k)\n",
    "            mat[h-1][k-1] = 1\n",
    "    return mat\n",
    "\n",
    "def W(output_dim, d = 4):\n",
    "    kernel = null_space((np.identity(d*d) -  G(d)).T).T\n",
    "    W = []\n",
    "    for j in range(output_dim):\n",
    "        vec = np.zeros(d**2)\n",
    "        for k in kernel:\n",
    "            vec = np.random.random()*k + vec\n",
    "        W.append(list(vec))\n",
    "    W = np.array(W)/len(kernel)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0a4538",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4c9c13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=(60000, 28, 28), y=(60000,)\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 9 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))\n",
    "# plot first few images\n",
    "for i in range(9):\n",
    "    # define subplot\n",
    "    plt.subplot(330 + 1 + i)\n",
    "    # plot raw pixel data\n",
    "    plt.imshow(trainX[i], cmap=plt.get_cmap('gray'))\n",
    "# show the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e555c38",
   "metadata": {},
   "source": [
    "## Define NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1f1d275c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "from torch import nn\n",
    "\n",
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class InvariantNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(InvariantNN, self).__init__()\n",
    "        \n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.l1 = nn.Linear(28*28, 64)\n",
    "        self.l2 = nn.Linear(64, 64)\n",
    "        self.l3 = nn.Linear(64, 10)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.acc_loss = nn.CrossEntropyLoss()\n",
    "        self.inv_loss = nn.MSELoss(reduction='sum')\n",
    "        \n",
    "    def get_gradient(self):\n",
    "        def_grad = {name: param.grad.clone() for name, param in self.named_parameters()}\n",
    "        flatten_def_grad = torch.concatenate([grad.flatten() for grad in def_grad.values()])\n",
    "        return(flatten_def_grad)\n",
    "        \n",
    "    def default_gradient(self, x0, target):\n",
    "        optimizer.zero_grad()\n",
    "        loss = self.acc_loss(self.forward(x0), target)\n",
    "        loss.backward(retain_graph=True)  \n",
    "        def_grad = {name: param.grad.clone() for name, param in self.named_parameters()}\n",
    "        flatten_def_grad = torch.concatenate([grad.flatten() for grad in def_grad.values()])\n",
    "        return def_grad, flatten_def_grad\n",
    "    \n",
    "    def invariance_gradient(self, x0, x0_r, target):\n",
    "        optimizer.zero_grad()\n",
    "        invariance_loss = self.inv_loss(x0, x0_r)\n",
    "        print(invariance_loss)\n",
    "        invariance_loss.requires_grad = True\n",
    "        invariance_loss.backward(retain_graph=True)\n",
    "        inv_grad = {name: param.grad.clone() for name, param in self.named_parameters()}\n",
    "        flatten_inv_grad = torch.concatenate([grad.flatten() for grad in inv_grad.values()])\n",
    "        return inv_grad, flatten_inv_grad\n",
    "\n",
    "    def project_gradient(self, scalar, norm, def_grad, inv_grad):\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for name, param in self.named_parameters():\n",
    "                if param.grad is not None:\n",
    "                    param.grad = def_grad[name] - (scalar/(norm**2))*inv_grad[name]\n",
    "        return {name: param.grad.clone() for name, param in self.named_parameters()}\n",
    "    \n",
    "    def retraction(self, x0, x0_r):\n",
    "\n",
    "        retraction_loss = (self.inv_loss(x0, x0_r))**2/2\n",
    "        retraction_loss.backward()\n",
    "        norm = self.get_gradient().norm()**2\n",
    "        optimizer_manifold = torch.optim.SGD(model.parameters(), lr=1/(2*norm), momentum=0)\n",
    "        return torch.optim.SGD(model.parameters(), lr=1/(2*norm), momentum=0)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.l2(x)    \n",
    "        x = self.relu(x)\n",
    "        x = self.l3(x)\n",
    "        x = self.relu(x)\n",
    "#         x = self.softmax(x)\n",
    "        return  x\n",
    "    \n",
    "    \n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8525b02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.4614e+11, device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.inv_loss(x0,rotated_data_90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165c04ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InvariantNN().to(device)\n",
    "model.l1.weight.data = torch.Tensor(W(64,d = 28)).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0)\n",
    "\n",
    "x0 = torch.Tensor(trainX).to(device) # images \n",
    "y0 = torch.Tensor(trainy).to(device) # true labels in form [0,0,0,1,0,0,0,0,0,0]\n",
    "\n",
    "rotated_data_90 = rotate(img = x0, angle = 90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f6e570",
   "metadata": {},
   "source": [
    "## Gradient projection train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f600514e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.4614e+11, device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[1;32mIn [7]\u001b[0m, in \u001b[0;36m<cell line: 18>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     46\u001b[0m     def_grad, flat_def_grad \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mdefault_gradient(x0, y0\u001b[38;5;241m.\u001b[39mlong())\n\u001b[1;32m---> 47\u001b[0m     inv_grad, flat_inv_grad \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvariance_gradient\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx0\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrotated_data_90\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my0\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlong\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m     scalar \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdot(flat_def_grad, flat_inv_grad)\n\u001b[0;32m     50\u001b[0m     norm \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnorm(flat_inv_grad)\n",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36mInvariantNN.invariance_gradient\u001b[1;34m(self, x0, x0_r, target)\u001b[0m\n\u001b[0;32m     37\u001b[0m invariance_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minv_loss(x0, x0_r)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(invariance_loss)\n\u001b[1;32m---> 39\u001b[0m \u001b[43minvariance_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m inv_grad \u001b[38;5;241m=\u001b[39m {name: param\u001b[38;5;241m.\u001b[39mgrad\u001b[38;5;241m.\u001b[39mclone() \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnamed_parameters()}\n\u001b[0;32m     41\u001b[0m flatten_inv_grad \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mconcatenate([grad\u001b[38;5;241m.\u001b[39mflatten() \u001b[38;5;28;01mfor\u001b[39;00m grad \u001b[38;5;129;01min\u001b[39;00m inv_grad\u001b[38;5;241m.\u001b[39mvalues()])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    521\u001b[0m     )\n\u001b[1;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\autograd\\__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[0;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "model = InvariantNN().to(device)\n",
    "model.l1.weight.data = torch.Tensor(W(64,d = 28)).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-5, momentum=0)\n",
    "\n",
    "x0 = torch.Tensor(trainX).to(device) # images \n",
    "y0 = torch.Tensor(trainy).to(device) # true labels in form [0,0,0,1,0,0,0,0,0,0]\n",
    "\n",
    "rotated_data_90 = rotate(img = x0, angle = 90)\n",
    "rotated_data_180 = rotate(img = x0, angle = 180)\n",
    "rotated_data_270 = rotate(img = x0, angle = 270)\n",
    "\n",
    "loss_accuracy = []\n",
    "accuracy = []\n",
    "\n",
    "loss_invariance = []\n",
    "invariance = []\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    pred1 = model(x0)\n",
    "    pred2 = model(rotated_data_90)\n",
    "    pred3 = model(rotated_data_180)\n",
    "    pred4 = model(rotated_data_270)\n",
    "    \n",
    "    _, pred_label1 = torch.max(pred1,1)\n",
    "    _, pred_label2 = torch.max(pred2,1)\n",
    "    _, pred_label3 = torch.max(pred3,1)\n",
    "    _, pred_label4 = torch.max(pred4,1)\n",
    "    \n",
    "    \n",
    "    acc = (pred_label1 == y0.long()).sum().item()/len(x0)\n",
    "    inv_1 = (pred_label1 == pred_label2).sum().item()/len(x0)\n",
    "    inv_2 = (pred_label1 == pred_label3).sum().item()/len(x0)\n",
    "    inv_3 = (pred_label1 == pred_label4).sum().item()/len(x0)\n",
    "    \n",
    "    inv = (inv_1 +inv_2 + inv_3)/3\n",
    "    \n",
    "    accuracy_loss = model.acc_loss(pred1, y0.long())\n",
    "    invariance_loss = model.inv_loss(pred1, pred2)\n",
    "    \n",
    "    if i%2 == 1:\n",
    "        optimizer.zero_grad()\n",
    "        epsilon = model.retraction(pred1, pred2)\n",
    "        epsilon.step()\n",
    "    else:\n",
    "        def_grad, flat_def_grad = model.default_gradient(x0, y0.long())\n",
    "        inv_grad, flat_inv_grad = model.invariance_gradient(x0, rotated_data_90, y0.long())\n",
    "\n",
    "        scalar = torch.dot(flat_def_grad, flat_inv_grad)\n",
    "        norm = torch.norm(flat_inv_grad)\n",
    "        model.project_gradient(scalar, norm, def_grad, inv_grad)\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "    if (i%100 == 0):\n",
    "        print(\"###########\", i, \"############\")\n",
    "        print(\"Accuracy: \" , round(acc, 2))\n",
    "        print(\"Invariance: \", round(inv, 2))\n",
    "        print(\"Loss: \" , accuracy_loss.cpu().detach().numpy())\n",
    "        print(\"Invariance_loss: \" , invariance_loss.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "    loss_accuracy.append(accuracy_loss.cpu().detach().numpy())\n",
    "    loss_invariance.append(invariance_loss.cpu().detach().numpy())\n",
    "    accuracy.append(acc)\n",
    "    invariance.append(inv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10d0cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InvariantNN().to(device)\n",
    "model.l1.weight.data = torch.Tensor(W(64,d = 28)).to(device)\n",
    "pred1 = model(x0)\n",
    "pred2 = model(rotated_data_90)\n",
    "y0 = torch.Tensor(trainy).to(device)\n",
    "inv_loss = (model.loss(pred1, y0.long()) - model.loss(pred2, y0.long()))**2/2\n",
    "print(inv_loss.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f991c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y0.long().cpu(), pred_label1.cpu())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccccde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rotated_data = rotate(img = x0, angle = 270)\n",
    "\n",
    "pred1 = model(x0)\n",
    "pred2 = model(rotated_data)\n",
    "_, arg1 = torch.max(pred1,1)\n",
    "_, arg2 = torch.max(pred2,1)\n",
    "\n",
    "cm = confusion_matrix(arg1.cpu(), arg2.cpu())\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.xlabel(\"rotated image\")\n",
    "plt.ylabel(\"default image\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ada8008",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(1)\n",
    "# plt.plot(loss_history, label = \"loss\")\n",
    "plt.plot(np.abs(loss_invariance), label = \"invariance_loss\")\n",
    "plt.legend()\n",
    "f.show()\n",
    "g = plt.figure(2)\n",
    "plt.plot(accuracy, label = \"accuracy\")\n",
    "plt.plot(invariance, label = \"invariance\")\n",
    "plt.legend()\n",
    "g.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b60c68c",
   "metadata": {},
   "source": [
    "Due obiettivi:\n",
    "* siamo entrati nella manifold (nessuno si è accorto di noi)\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c938c96b",
   "metadata": {},
   "source": [
    "## Root finding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc427e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa24158",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((x0[0] - rotate(img = x0, angle = 270))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow((x0[0] - rotate(img = x0, angle = 45))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e354e8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy.linalg.\n",
    "lstsq\n",
    "scipy.linalg.lstsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b176aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definisci la matrice A\n",
    "A = np.array([[2, 4], [1, 2]])\n",
    "\n",
    "# Calcola il kernel\n",
    "kernel = null_space(A)\n",
    "print(\"Kernel della matrice:\")\n",
    "print(kernel.flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5cc46ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Weights = W(5,rot_mat(28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5263d0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = model.flatten(x0[0:1]).detach().numpy()[0]\n",
    "image1_rot = model.flatten(rotate(img = x0[0:1], angle = 90)).detach().numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48acff2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1 = Weights@image1\n",
    "out2 = Weights@image1_rot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068406a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fdb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04198a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "out1-out2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8de32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_vec = x.reshape(16)\n",
    "x_r = mat@x_vec\n",
    "x_r_img = x_r.reshape(4,4)\n",
    "plt.imshow(x_r_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3dcd85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "157fb4c8",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2fe8d9",
   "metadata": {},
   "source": [
    "# Standard train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd341a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InvariantNN()\n",
    "# model.l1.weight.data = torch.Tensor(W(64,rot_mat(28)))\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-4, momentum=0.9)\n",
    "\n",
    "x0 = torch.Tensor(trainX)\n",
    "y0 = torch.Tensor(trainy)\n",
    "\n",
    "rotated_data = rotate(img = x0, angle = 110)\n",
    "loss_history = []\n",
    "accuracy = []\n",
    "\n",
    "for i in range(400):\n",
    "    l_inv = 0\n",
    "    l_acc = 1\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    pred1 = model(x0)\n",
    "    pred2 = model(rotated_data)\n",
    "    avg_pred = torch.sum(pred1, axis = 0)/6000\n",
    "    \n",
    "    _, arg1 = torch.max(pred1,1)\n",
    "    _, arg2 = torch.max(pred2,1)\n",
    "    \n",
    "    \n",
    "    acc = (arg1 == y0.long()).sum().item()/len(x0)\n",
    "    inv = (arg1 == arg2).sum().item()/len(x0)   \n",
    "    \n",
    "    loss = loss_CE(pred1, y0.long()) #- 0.001*loss_CE( avg_pred , uniform_dist )\n",
    "    \n",
    "    \n",
    "    if i%5 == 1:\n",
    "        print(\"Accuracy: \" , round(acc, 2))\n",
    "        print(\"Invariance: \", round(inv, 2))\n",
    "        print(\"Loss: \" , loss.detach().numpy())\n",
    "          \n",
    "    loss_history.append(loss.detach().numpy())\n",
    "    accuracy.append(acc)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a61382",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = InvariantNN()\n",
    "model.l1.weight.data = torch.Tensor(W(64,28))\n",
    "\n",
    "x0 = torch.Tensor(trainX)\n",
    "y0 = torch.Tensor(trainy)\n",
    "\n",
    "rotated_data = rotate(img = x0, angle = 270)\n",
    "\n",
    "pred1 = model(x0)\n",
    "pred2 = model(rotated_data)\n",
    "avg_pred = torch.sum(pred1, axis = 0)/6000\n",
    "\n",
    "_, arg1 = torch.max(pred1,1)\n",
    "_, arg2 = torch.max(pred2,1)\n",
    "\n",
    "acc = (arg1 == y0.long()).sum().item()/len(x0)\n",
    "inv = (arg1 == arg2).sum().item()/len(x0) \n",
    "loss = loss_CE(pred1, pred2) + loss_CE(pred1, y0.long()) #- 0.001*loss_CE( avg_pred , uniform_dist )\n",
    "\n",
    "print(\"Accuracy: \" , round(acc, 5))\n",
    "print(\"Invariance: \", round(inv, 9))\n",
    "print(\"Loss: \" , loss.detach().numpy())\n",
    "\n",
    "cm = confusion_matrix(arg1, arg2)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c2ffb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4627a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Definizione di una rete neurale di esempio\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.linear1 = nn.Linear(10, 5)\n",
    "        self.linear2 = nn.Linear(5, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.linear1(x))\n",
    "        return self.linear2(x)\n",
    "\n",
    "# Funzione per concatenare i gradienti di tutti i parametri in un unico vettore\n",
    "def get_concatenated_gradients(grad_dict):\n",
    "    return torch.cat([g.flatten() for g in grad_dict.values() if g is not None])\n",
    "\n",
    "# Funzione per ricostruire i gradienti dai vettori concatenati\n",
    "def set_gradients_from_vector(model, grad_vector, grad_dict):\n",
    "    offset = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if grad_dict[name] is not None:\n",
    "            grad_shape = grad_dict[name].shape\n",
    "            grad_size = grad_dict[name].numel()\n",
    "            param.grad = grad_vector[offset:offset + grad_size].view(grad_shape)\n",
    "            offset += grad_size\n",
    "\n",
    "# Inizializziamo il modello e l'ottimizzatore\n",
    "model = SimpleNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Creiamo due insiemi di input differenti\n",
    "x1 = torch.randn(3, 10)\n",
    "x2 = torch.randn(3, 10)\n",
    "\n",
    "# Creiamo dei target casuali per calcolare la loss\n",
    "target1 = torch.randn(3, 1)\n",
    "target2 = torch.randn(3, 1)\n",
    "\n",
    "# STEP 1: Calcolo dei gradienti rispetto ai pesi per il primo input `x1`\n",
    "output1 = model(x1)\n",
    "loss1 = nn.functional.mse_loss(output1, target1)\n",
    "optimizer.zero_grad()\n",
    "loss1.backward(retain_graph=True)\n",
    "grads1 = {name: param.grad.clone() for name, param in model.named_parameters()}\n",
    "\n",
    "# STEP 2: Calcolo dei gradienti rispetto ai pesi per il secondo input `x2`\n",
    "output2 = model(x2)\n",
    "loss2 = nn.functional.mse_loss(output2, target2)\n",
    "optimizer.zero_grad()\n",
    "loss2.backward()\n",
    "grads2 = {name: param.grad.clone() for name, param in model.named_parameters()}\n",
    "\n",
    "# Concateniamo i gradienti in un unico vettore\n",
    "grad1_vec = get_concatenated_gradients(grads1)\n",
    "grad2_vec = get_concatenated_gradients(grads2)\n",
    "\n",
    "# STEP 3: Calcolo della componente ortogonale di `grad1_vec` rispetto a `grad2_vec`\n",
    "with torch.no_grad():\n",
    "    dot_product = torch.dot(grad1_vec, grad2_vec)\n",
    "    norm_grad2_sq = torch.norm(grad2_vec) ** 2\n",
    "\n",
    "    # Evitiamo la divisione per zero\n",
    "    if norm_grad2_sq > 0:\n",
    "        # Calcoliamo la proiezione di `grad1_vec` su `grad2_vec`\n",
    "        projection = (dot_product / norm_grad2_sq) * grad2_vec\n",
    "        # Calcoliamo la componente ortogonale\n",
    "        ortho_component = grad1_vec - projection\n",
    "    else:\n",
    "        ortho_component = grad1_vec\n",
    "\n",
    "    # Ricostruiamo i gradienti nel modello usando la componente ortogonale\n",
    "    set_gradients_from_vector(model, ortho_component, grads1)\n",
    "\n",
    "# STEP 4: Eseguiamo l'aggiornamento dei pesi usando la componente ortogonale\n",
    "optimizer.step()\n",
    "\n",
    "# Stampa dei pesi aggiornati (opzionale)\n",
    "print(\"Pesi aggiornati:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
