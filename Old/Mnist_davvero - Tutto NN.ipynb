{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "735f57b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import geoopt\n",
    "from geoopt.optim import RiemannianSGD, RiemannianAdam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from torch.func import grad\n",
    "\n",
    "import torch\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms.functional import rotate\n",
    "from scipy.linalg import lstsq, null_space\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e104f20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "88b9803a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(d): # questa è  rot_mat\n",
    "    mat = np.zeros(d**4).reshape(d**2,d**2)\n",
    "    for j in range(d):\n",
    "        for i in range(d):\n",
    "            k = (i+1)*d-j\n",
    "            h = i+(j)*d+1\n",
    "\n",
    "            mat[h-1][k-1] = 1\n",
    "    return mat\n",
    "\n",
    "def W(output_dim, d = 4):\n",
    "    kernel = null_space((np.identity(d*d) -  G(d)).T).T\n",
    "    W = []\n",
    "    for j in range(output_dim):\n",
    "        vec = np.zeros(d**2)\n",
    "        for k in kernel:\n",
    "            vec = np.random.random()*k + vec\n",
    "        W.append(list(vec))\n",
    "    W = np.array(W)/len(kernel)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b1aea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=torch.Size([10, 28, 28]), y=torch.Size([10])\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "trainX = trainX[:10]\n",
    "trainy = trainy[:10]\n",
    "\n",
    "trainy = torch.Tensor(trainy).to(device)\n",
    "trainX = trainX / 256\n",
    "testX = testX / 256\n",
    "\n",
    "trainX = torch.Tensor(trainX).to(device)\n",
    "trainX_90 = rotate(img = trainX, angle = 90)\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d76a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class InvariantNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden, output):\n",
    "        super(InvariantNN, self).__init__()\n",
    "        \n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "    \n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.l1 = nn.Linear(self.input_dim, self.hidden)\n",
    "        self.l2 = nn.Linear(self.hidden, self.hidden)\n",
    "        self.l3 = nn.Linear(self.hidden, self.output)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.acc_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def get_shapes(self):\n",
    "        shapes = [(self.input_dim, self.hidden), \n",
    "                  (self.hidden,1),\n",
    "                  (self.hidden, self.hidden),\n",
    "                  (self.hidden,1),\n",
    "                  (self.hidden, self.output),\n",
    "                  (self.output,1)\n",
    "                 ]\n",
    "        return shapes\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.l2(x)    \n",
    "        x = self.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return  x\n",
    "    \n",
    "model = InvariantNN(28*28, 64, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1a969b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95306"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*64 + 64 + 64*64 + 64 * 64*10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4528964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(weights_list):\n",
    "    flatten_weights = []\n",
    "    for weight in weights_list:\n",
    "        flatten_weights.append(weight.flatten())\n",
    "        \n",
    "    return torch.concatenate(flatten_weights)\n",
    "\n",
    "def deflatten(weights_flat, shapes):\n",
    "    weigths_list = []\n",
    "    shape_counter = 0\n",
    "    for shape in shapes:\n",
    "        weight = torch.Tensor(weights_flat[shape_counter: shape_counter + np.prod(shape)])\n",
    "        shape_counter = shape_counter + np.prod(shape)\n",
    "        \n",
    "        weigths_list.append(weight.reshape(shape))\n",
    "            \n",
    "    return weigths_list\n",
    "\n",
    "# Funzione che definisce la varietà: sfera unitaria centrata in 0\n",
    "def g(thetas):\n",
    "    \n",
    "    W1, b1, W2, b2, W3, b3 = deflatten(thetas, model.get_shapes())\n",
    "    model.l1.weight.data = W1.T\n",
    "    model.l2.weight.data = W2.T\n",
    "    model.l3.weight.data = W3.T\n",
    "    model.l1.bias.data = b1.T\n",
    "    model.l2.bias.data = b2.T\n",
    "    model.l3.bias.data = b3.T\n",
    "    \n",
    "    \n",
    "    NN1 = model(trainX)\n",
    "    NN2 = model(trainX_90)\n",
    "    Delta_NN = NN1 - NN2\n",
    "    norm = Delta_NN.norm()**2\n",
    "    \n",
    "    # Zero grad\n",
    "    for param in model.parameters():\n",
    "        param.grad = torch.zeros(param.shape).to(device)\n",
    "        \n",
    "    # Compute gradient\n",
    "    norm.backward()\n",
    "    \n",
    "    return norm # sfera unitaria\n",
    "\n",
    "\n",
    "def dg(thetas):\n",
    "    _ = g(thetas)\n",
    "    def_grad = [param.grad for param in model.parameters()]\n",
    "    \n",
    "    \n",
    "    return flatten(def_grad)\n",
    "\n",
    "# # Gradiente di f\n",
    "# def dg(thetas):\n",
    "#     gradient = grad(g)(thetas)\n",
    "#     return gradient #+ 1e-5*(gradient.norm()==0)\n",
    "\n",
    "\n",
    "# Classe LevelSetManifold già implementata sopra\n",
    "class LevelSetManifold(geoopt.manifolds.Manifold):\n",
    "    \n",
    "    ndim = 1\n",
    "    name = \"Caste\"\n",
    "    \n",
    "    def __init__(self, f, df, lr_proj = 1):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "        self.df = df\n",
    "        self.lr_proj = lr_proj\n",
    "\n",
    "    def _check_point_on_manifold(self, x, atol=1e-7, rtol=1e-7):\n",
    "        return torch.abs(self.f(x)) < atol\n",
    "\n",
    "    def _check_vector_on_tangent(self, x, u, atol=1e-7, rtol=1e-7):\n",
    "        grad_f = self.df(x)\n",
    "        return torch.abs(u @ grad_f).sum() < atol\n",
    "    \n",
    "    def projx(self,x):\n",
    "        if self._check_point_on_manifold(x):\n",
    "            return x\n",
    "        for r in range(100):\n",
    "            x = self.single_projx(x)\n",
    "            if r%50==0:\n",
    "                print(\"g: \", self.f(x))\n",
    "                print(\"dg: \", self.df(x).norm())\n",
    "            if r == 99:\n",
    "                print(f\"Retraction applied {r + 1} times\")\n",
    "            if self._check_point_on_manifold(x):\n",
    "                print(f\"Retraction applied {r + 1} times\")\n",
    "                break\n",
    "        return x\n",
    "    \n",
    "    def single_projx(self, x):\n",
    "        \"\"\"\n",
    "        Retraction\n",
    "        \"\"\"\n",
    "        grad_f = self.df(x)\n",
    "        f_val = self.f(x)\n",
    "        return x - 1*self.lr_proj*(f_val / grad_f.norm()**2 * grad_f)\n",
    "\n",
    "    def proju(self, x, u):\n",
    "        \"\"\"\n",
    "        Projected gradient\n",
    "        \"\"\"\n",
    "        grad_f = self.df(x)\n",
    "        return u - 1*(u @ grad_f) / grad_f.norm()**2 * grad_f\n",
    "\n",
    "    def inner(self, x, u, v=None):\n",
    "        if v is None:\n",
    "            v = u\n",
    "        return (u * v).sum()\n",
    "\n",
    "    def expmap(self, x, u):\n",
    "        return self.retr(x, u)\n",
    "\n",
    "    def egrad2rgrad(self, x, u):\n",
    "        return self.proju(x, u)\n",
    "\n",
    "    def retr(self, x, u):\n",
    "        x_new = x + u\n",
    "        return self.projx(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8270748c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\scanu\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\autograd\\__init__.py:266: UserWarning: grad and param do not obey the gradient layout contract. This is not an error, but may impair performance.\n",
      "grad.sizes() = [10, 64], strides() = [64, 1]\n",
      "param.sizes() = [10, 64], strides() = [1, 10] (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch/csrc/autograd/functions/accumulate_grad.h:219.)\n",
      "  Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prima:  g:  0.43777576088905334 dg:  tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############ Landing phase #############\n",
      "g:  tensor(0.4392, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(6.6197, device='cuda:0')\n",
      "g:  tensor(0.7958, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(9.8786, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "0 g:  2.533600330352783 dg:  tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "g:  tensor(2.5997, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(22.6729, device='cuda:0')\n",
      "g:  tensor(9.0189, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(68.0983, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(42.6907, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(245.6805, device='cuda:0')\n",
      "g:  tensor(76.8506, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(483.3129, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(163.5717, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(891.2649, device='cuda:0')\n",
      "g:  tensor(194.4504, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(909.6375, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(250.0540, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(1195.8955, device='cuda:0')\n",
      "g:  tensor(239.5824, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(1288.3459, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(394.8608, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(1556.9850, device='cuda:0')\n",
      "g:  tensor(698.9584, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(2270.4998, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(842.8812, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3188.7126, device='cuda:0')\n",
      "g:  tensor(776.1387, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(4890.0693, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(645.7515, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3268.3206, device='cuda:0')\n",
      "g:  tensor(694.8625, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3070.6641, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(736.2491, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3077.4541, device='cuda:0')\n",
      "g:  tensor(1049.2423, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3955.4849, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(794.8513, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3076.9128, device='cuda:0')\n",
      "g:  tensor(705.8913, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(2609.4055, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "\n",
      "\n",
      "\n",
      "############## Training phase ################\n",
      "Epoch 1 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 11 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 21 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 31 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 41 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 51 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 61 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 71 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 81 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 91 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 101 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 111 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 121 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 131 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 141 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 151 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 161 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 171 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 181 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 191 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 201 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 211 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 221 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 231 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 241 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 251 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 261 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 271 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 281 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "Epoch 291 Loss: 11.995955467224121 g(theta): 765.73718262\n",
      "\n",
      "\n",
      "\n",
      "Punto finale: Parameter on Caste manifold containing:\n",
      "Parameter(ManifoldParameter([-0.0319, -0.0122, -0.0193,  ..., -0.0464, -0.0207,\n",
      "                   -0.0562], device='cuda:0', requires_grad=True))\n",
      "Appartiene alla varietà? tensor(False, device='cuda:0')\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgzUlEQVR4nO3df2xV9eH/8dcF2gtfpBcKSHtLC4RFxQG1w+EQceAUbLRIDIOK0m5zWyToUDShnSDFDcp0Eo0dmnU4t8SJCZaOIE4gtFQFJ7XcydS0VG5pZ2nYYNzbH+NSbt/fPwzXTy0X7pWW+6Z9PpKTcM8v3vedk9xnTk97HcYYIwAAAIv1i/UAAAAALoZgAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGC9AbEeQHfp6OhQY2OjhgwZIofDEevhAACACBhj1NzcLLfbrX79wt9H6TXB0tjYqNTU1FgPAwAAfAMNDQ0aPXp02O29JliGDBki6cs3nJCQEOPRAACASPj9fqWmpoY+x8PpNcFy7sdACQkJBAsAAFeYiz3OwUO3AADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOtFHSwVFRXKysqS2+2Ww+FQaWlpaFt7e7tWrFihSZMmafDgwXK73crJyVFjY+NFz3vq1CktXbpUycnJGjhwoCZMmKAdO3ZEOzwAANALRR0sra2tSk9PV1FRUZdtbW1tqqqq0qpVq1RVVaWSkhLV1NRo7ty5FzznmTNndMcdd6iurk5btmxRdXW1iouLlZKSEu3wAABALxT1n+bPzMxUZmbmebe5XC7t2rWr07oXX3xRU6dOVX19vdLS0s573CuvvKKTJ09q3759iouLkySNGTMm2qEBAIBeqsefYfH5fHI4HBo6dGjYfbZt26Zp06Zp6dKlGjVqlCZOnKh169YpGAyGPSYQCMjv93daAABA79SjwXL69Gnl5eVp0aJFF/xCwiNHjmjLli0KBoPasWOHVq5cqeeee05r164Ne0xhYaFcLldoSU1N7Ym3AAAALOAwxphvfLDDoa1bt2revHldtrW3t+uHP/yh6uvrVV5efsFgueaaa3T69Gl5vV71799fkrRhwwY9++yzOnbs2HmPCQQCCgQCodfnvp7a5/Pxbc0AAFwh/H6/XC7XRT+/o36GJRLt7e1asGCBvF6v9uzZc9GASE5OVlxcXChWJGnChAlqamrSmTNnFB8f3+UYp9Mpp9PZ7WMHAAD26fYfCZ2LlcOHD2v37t0aPnz4RY+ZPn26amtr1dHREVpXU1Oj5OTk88YKAADoW6IOlpaWFnk8Hnk8HkmS1+uVx+NRfX29zp49q/nz56uyslKvvfaagsGgmpqaQndKzsnJyVF+fn7o9ZIlS3TixAktW7ZMNTU1euutt7Ru3TotXbr00t8hAAC44kX9I6HKykrNmjUr9Hr58uWSpNzcXBUUFGjbtm2SpBtuuKHTcWVlZZo5c6Ykqb6+Xv36fdVKqamp2rlzpx577DFNnjxZKSkpWrZsmVasWBHt8AAAQC90SQ/d2iTSh3YAAIA9Iv385ruEAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPWiDpaKigplZWXJ7XbL4XCotLQ0tK29vV0rVqzQpEmTNHjwYLndbuXk5KixsTHi82/evFkOh0Pz5s2LdmgAAKCXijpYWltblZ6erqKioi7b2traVFVVpVWrVqmqqkolJSWqqanR3LlzIzr30aNH9cQTT2jGjBnRDgsAAPRiA6I9IDMzU5mZmefd5nK5tGvXrk7rXnzxRU2dOlX19fVKS0sLe95gMKj7779fa9as0bvvvqtTp05FOzQAANBL9fgzLD6fTw6HQ0OHDr3gfk8//bRGjhypBx98MKLzBgIB+f3+TgsAAOidejRYTp8+rby8PC1atEgJCQlh93v//fe1adMmFRcXR3zuwsJCuVyu0JKamtodQwYAABbqsWBpb29Xdna2Ojo6tHHjxrD7NTc364EHHlBxcbFGjBgR8fnz8/Pl8/lCS0NDQ3cMGwAAWCjqZ1gi0d7ergULFsjr9WrPnj0XvLvy+eefq66uTllZWaF1HR0dXw5uwABVV1dr/PjxXY5zOp1yOp3dP3gAAGCdbg+Wc7Fy+PBhlZWVafjw4Rfc/7rrrtOhQ4c6rVu5cqWam5v1wgsv8KMeAAAQfbC0tLSotrY29Nrr9crj8SgxMVFut1vz589XVVWVtm/frmAwqKamJklSYmKi4uPjJUk5OTlKSUlRYWGhBg4cqIkTJ3b6P849oPv19QAAoG+KOlgqKys1a9as0Ovly5dLknJzc1VQUKBt27ZJkm644YZOx5WVlWnmzJmSpPr6evXrxx/ZBQAAkXEYY0ysB9Ed/H6/XC6XfD7fBZ+ZAQAA9oj085vbHAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsB7BAgAArEewAAAA6xEsAADAegQLAACwHsECAACsR7AAAADrESwAAMB6UQdLRUWFsrKy5Ha75XA4VFpaGtrW3t6uFStWaNKkSRo8eLDcbrdycnLU2Nh4wXMWFxdrxowZGjZsmIYNG6bbb79dH374YdRvBgAA9E5RB0tra6vS09NVVFTUZVtbW5uqqqq0atUqVVVVqaSkRDU1NZo7d+4Fz1leXq777rtPZWVl2r9/v9LS0jR79mx98cUX0Q4PAAD0Qg5jjPnGBzsc2rp1q+bNmxd2nwMHDmjq1Kk6evSo0tLSIjpvMBjUsGHDVFRUpJycnIiO8fv9crlc8vl8SkhIiOgYAAAQW5F+fg/o6YH4fD45HA4NHTo04mPa2trU3t6uxMTEsPsEAgEFAoHQa7/ffynDBAAAFuvRh25Pnz6tvLw8LVq0KKq7Hnl5eUpJSdHtt98edp/CwkK5XK7Qkpqa2h1DBgAAFuqxYGlvb1d2drY6Ojq0cePGiI975pln9Prrr6ukpEQDBw4Mu19+fr58Pl9oaWho6I5hAwAAC/XIj4Ta29u1YMECeb1e7dmzJ+K7K7/97W+1bt067d69W5MnT77gvk6nU06nszuGCwAALNftwXIuVg4fPqyysjINHz48ouOeffZZ/frXv9Y777yjG2+8sbuHBQAArmBRB0tLS4tqa2tDr71erzwejxITE+V2uzV//nxVVVVp+/btCgaDampqkiQlJiYqPj5ekpSTk6OUlBQVFhZK+vLHQKtWrdJf/vIXjR07NnTMVVddpauuuuqS3yQAALiyRf1rzeXl5Zo1a1aX9bm5uSooKNC4cePOe1xZWZlmzpwpSZo5c6bGjh2rV199VZI0duxYHT16tMsxq1evVkFBQUTj4teaAQC48kT6+X1Jf4fFJgQLAABXnkg/v/kuIQAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGC9qIOloqJCWVlZcrvdcjgcKi0tDW1rb2/XihUrNGnSJA0ePFhut1s5OTlqbGy86HnffPNNXX/99XI6nbr++uu1devWaIcGAAB6qaiDpbW1Venp6SoqKuqyra2tTVVVVVq1apWqqqpUUlKimpoazZ0794Ln3L9/vxYuXKjFixfrH//4hxYvXqwFCxbo73//e7TDAwAAvZDDGGO+8cEOh7Zu3ap58+aF3efAgQOaOnWqjh49qrS0tPPus3DhQvn9fr399tuhdXfeeaeGDRum119/PaKx+P1+uVwu+Xw+JSQkRPU+AABAbET6+T2gpwfi8/nkcDg0dOjQsPvs379fjz32WKd1c+bM0fPPPx/2mEAgoEAgEHrt9/svdahdGGP0v/Zgt58XAIAr0aC4/nI4HDH5v3s0WE6fPq28vDwtWrTogtXU1NSkUaNGdVo3atQoNTU1hT2msLBQa9as6baxns//2oO6/ql3evT/AADgSvHp03P0/+J7/F7HefXYbwm1t7crOztbHR0d2rhx40X3/3qxGWMuWHH5+fny+XyhpaGh4ZLHDAAA7NQjmdTe3q4FCxbI6/Vqz549F32mJCkpqcvdlOPHj3e56/J/OZ1OOZ3ObhlvOIPi+uvTp+f06P8BAMCVYlBc/5j9390eLOdi5fDhwyorK9Pw4cMvesy0adO0a9euTs+x7Ny5UzfffHN3Dy8qDocjZre+AADAV6L+NG5paVFtbW3otdfrlcfjUWJiotxut+bPn6+qqipt375dwWAwdOckMTFR8fHxkqScnBylpKSosLBQkrRs2TLdeuut+s1vfqN77rlHf/3rX7V7926999573fEeAQDAFS7qX2suLy/XrFmzuqzPzc1VQUGBxo0bd97jysrKNHPmTEnSzJkzNXbsWL366quh7Vu2bNHKlSt15MgRjR8/XmvXrtW9994b8bj4tWYAAK48kX5+X9LfYbEJwQIAwJUn0s9vvksIAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWC/qYKmoqFBWVpbcbrccDodKS0s7bS8pKdGcOXM0YsQIORwOeTyeiM77/PPP69prr9WgQYOUmpqqxx57TKdPn452eAAAoBeKOlhaW1uVnp6uoqKisNunT5+u9evXR3zO1157TXl5eVq9erU+++wzbdq0SW+88Yby8/OjHR4AAOiFBkR7QGZmpjIzM8NuX7x4sSSprq4u4nPu379f06dP16JFiyRJY8eO1X333acPP/ww2uEBAIBeyIpnWG655RZ99NFHoUA5cuSIduzYobvuuivsMYFAQH6/v9MCAAB6p6jvsPSE7Oxs/fvf/9Ytt9wiY4zOnj2rJUuWKC8vL+wxhYWFWrNmzWUcJQAAiBUr7rCUl5dr7dq12rhxo6qqqlRSUqLt27frV7/6Vdhj8vPz5fP5QktDQ8NlHDEAALicrLjDsmrVKi1evFg//elPJUmTJk1Sa2urfv7zn+vJJ59Uv35du8rpdMrpdF7uoQIAgBiw4g5LW1tblyjp37+/jDEyxsRoVAAAwBZR32FpaWlRbW1t6LXX65XH41FiYqLS0tJ08uRJ1dfXq7GxUZJUXV0tSUpKSlJSUpIkKScnRykpKSosLJQkZWVlacOGDcrIyNBNN92k2tparVq1SnPnzlX//v0v+U0CAIArW9TBUllZqVmzZoVeL1++XJKUm5urV199Vdu2bdOPf/zj0Pbs7GxJ0urVq1VQUCBJqq+v73RHZeXKlXI4HFq5cqW++OILjRw5UllZWVq7du03elMAAKB3cZhe8jMXv98vl8sln8+nhISEWA8HAABEINLPbyueYQEAALgQggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgvaiDpaKiQllZWXK73XI4HCotLe20vaSkRHPmzNGIESPkcDjk8XgiOu+pU6e0dOlSJScna+DAgZowYYJ27NgR7fAAAEAvFHWwtLa2Kj09XUVFRWG3T58+XevXr4/4nGfOnNEdd9yhuro6bdmyRdXV1SouLlZKSkq0wwMAAL3QgGgPyMzMVGZmZtjtixcvliTV1dVFfM5XXnlFJ0+e1L59+xQXFydJGjNmTLRDAwAAvZQVz7Bs27ZN06ZN09KlSzVq1ChNnDhR69atUzAYDHtMIBCQ3+/vtAAAgN7JimA5cuSItmzZomAwqB07dmjlypV67rnntHbt2rDHFBYWyuVyhZbU1NTLOGIAAHA5WREsHR0duvrqq/X73/9eU6ZMUXZ2tp588km99NJLYY/Jz8+Xz+cLLQ0NDZdxxAAA4HKK+hmWnpCcnKy4uDj1798/tG7ChAlqamrSmTNnFB8f3+UYp9Mpp9N5OYcJAABixIo7LNOnT1dtba06OjpC62pqapScnHzeWAEAAH1L1MHS0tIij8cT+vsqXq9XHo9H9fX1kqSTJ0/K4/Ho008/lSRVV1fL4/GoqakpdI6cnBzl5+eHXi9ZskQnTpzQsmXLVFNTo7feekvr1q3T0qVLL+W9AQCAXiLqYKmsrFRGRoYyMjIkScuXL1dGRoaeeuopSV/+xk9GRobuuusuSVJ2drYyMjL08ssvh85RX1+vY8eOhV6npqZq586dOnDggCZPnqxf/OIXWrZsmfLy8i7pzQEAgN7BYYwxsR5Ed/D7/XK5XPL5fEpISIj1cAAAQAQi/fy24hkWAACACyFYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWI9gAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANaLOlgqKiqUlZUlt9sth8Oh0tLSTttLSko0Z84cjRgxQg6HQx6PJ6rzb968WQ6HQ/PmzYt2aAAAoJeKOlhaW1uVnp6uoqKisNunT5+u9evXRz2Yo0eP6oknntCMGTOiPhYAAPReA6I9IDMzU5mZmWG3L168WJJUV1cX1XmDwaDuv/9+rVmzRu+++65OnToV7dAAAEAvZc0zLE8//bRGjhypBx98MKL9A4GA/H5/pwUAAPROVgTL+++/r02bNqm4uDjiYwoLC+VyuUJLampqD44QAADEUsyDpbm5WQ888ICKi4s1YsSIiI/Lz8+Xz+cLLQ0NDT04SgAAEEtRP8PS3T7//HPV1dUpKysrtK6jo0OSNGDAAFVXV2v8+PFdjnM6nXI6nZdtnAAAIHZiHizXXXedDh061GndypUr1dzcrBdeeIEf9QAAgOiDpaWlRbW1taHXXq9XHo9HiYmJSktL08mTJ1VfX6/GxkZJUnV1tSQpKSlJSUlJkqScnBylpKSosLBQAwcO1MSJEzv9H0OHDpWkLusBAEDfFPUzLJWVlcrIyFBGRoYkafny5crIyNBTTz0lSdq2bZsyMjJ01113SZKys7OVkZGhl19+OXSO+vp6HTt2rDvGDwAA+gCHMcbEehDdwe/3y+VyyefzKSEhIdbDAQAAEYj08zvmvyUEAABwMQQLAACwHsECAACsR7AAAADrESwAAMB6BAsAALAewQIAAKxHsAAAAOsRLAAAwHoECwAAsF7Mv625u5z7hgG/3x/jkQAAgEid+9y+2DcF9ZpgaW5uliSlpqbGeCQAACBazc3NcrlcYbf3mi8/7OjoUGNjo4YMGSKHw9Ft5/X7/UpNTVVDQwNfqhgB5ityzFXkmKvoMF+RY66i0xPzZYxRc3Oz3G63+vUL/6RKr7nD0q9fP40ePbrHzp+QkMDFHAXmK3LMVeSYq+gwX5FjrqLT3fN1oTsr5/DQLQAAsB7BAgAArEewXITT6dTq1avldDpjPZQrAvMVOeYqcsxVdJivyDFX0YnlfPWah24BAEDvxR0WAABgPYIFAABYj2ABAADWI1gAAID1CJaL2Lhxo8aNG6eBAwdqypQpevfdd2M9pJgrKCiQw+HotCQlJYW2G2NUUFAgt9utQYMGaebMmfrkk09iOOLLp6KiQllZWXK73XI4HCotLe20PZK5CQQCeuSRRzRixAgNHjxYc+fO1b/+9a/L+C4un4vN149+9KMu19r3vve9Tvv0lfkqLCzUd7/7XQ0ZMkRXX3215s2bp+rq6k77cH19KZK54tr60ksvvaTJkyeH/hDctGnT9Pbbb4e223RNESwX8MYbb+jRRx/Vk08+qYMHD2rGjBnKzMxUfX19rIcWc9/+9rd17Nix0HLo0KHQtmeeeUYbNmxQUVGRDhw4oKSkJN1xxx2h73vqzVpbW5Wenq6ioqLzbo9kbh599FFt3bpVmzdv1nvvvaeWlhbdfffdCgaDl+ttXDYXmy9JuvPOOztdazt27Oi0va/M1969e7V06VJ98MEH2rVrl86ePavZs2ertbU1tA/X15cimSuJa0uSRo8erfXr16uyslKVlZW67bbbdM8994SixKpryiCsqVOnmoceeqjTuuuuu87k5eXFaER2WL16tUlPTz/vto6ODpOUlGTWr18fWnf69GnjcrnMyy+/fJlGaAdJZuvWraHXkczNqVOnTFxcnNm8eXNony+++ML069fP/O1vf7tsY4+Fr8+XMcbk5uaae+65J+wxfXm+jh8/biSZvXv3GmO4vi7k63NlDNfWhQwbNsz84Q9/sO6a4g5LGGfOnNFHH32k2bNnd1o/e/Zs7du3L0ajssfhw4fldrs1btw4ZWdn68iRI5Ikr9erpqamTvPmdDr1/e9/v8/PWyRz89FHH6m9vb3TPm63WxMnTuyz81deXq6rr75a11xzjX72s5/p+PHjoW19eb58Pp8kKTExURLX14V8fa7O4drqLBgMavPmzWptbdW0adOsu6YIljD+85//KBgMatSoUZ3Wjxo1Sk1NTTEalR1uuukm/fnPf9Y777yj4uJiNTU16eabb9aJEydCc8O8dRXJ3DQ1NSk+Pl7Dhg0Lu09fkpmZqddee0179uzRc889pwMHDui2225TIBCQ1Hfnyxij5cuX65ZbbtHEiRMlcX2Fc765kri2/q9Dhw7pqquuktPp1EMPPaStW7fq+uuvt+6a6jXf1txTHA5Hp9fGmC7r+prMzMzQvydNmqRp06Zp/Pjx+tOf/hR6aI15C++bzE1fnb+FCxeG/j1x4kTdeOONGjNmjN566y3de++9YY/r7fP18MMP6+OPP9Z7773XZRvXV2fh5opr6yvXXnutPB6PTp06pTfffFO5ubnau3dvaLst1xR3WMIYMWKE+vfv36UQjx8/3qU2+7rBgwdr0qRJOnz4cOi3hZi3riKZm6SkJJ05c0b//e9/w+7TlyUnJ2vMmDE6fPiwpL45X4888oi2bdumsrIyjR49OrSe66urcHN1Pn352oqPj9e3vvUt3XjjjSosLFR6erpeeOEF664pgiWM+Ph4TZkyRbt27eq0fteuXbr55ptjNCo7BQIBffbZZ0pOTta4ceOUlJTUad7OnDmjvXv39vl5i2RupkyZori4uE77HDt2TP/85z/7/PxJ0okTJ9TQ0KDk5GRJfWu+jDF6+OGHVVJSoj179mjcuHGdtnN9feVic3U+ffna+jpjjAKBgH3XVLc+wtvLbN682cTFxZlNmzaZTz/91Dz66KNm8ODBpq6uLtZDi6nHH3/clJeXmyNHjpgPPvjA3H333WbIkCGheVm/fr1xuVympKTEHDp0yNx3330mOTnZ+P3+GI+85zU3N5uDBw+agwcPGklmw4YN5uDBg+bo0aPGmMjm5qGHHjKjR482u3fvNlVVVea2224z6enp5uzZs7F6Wz3mQvPV3NxsHn/8cbNv3z7j9XpNWVmZmTZtmklJSemT87VkyRLjcrlMeXm5OXbsWGhpa2sL7cP19aWLzRXX1lfy8/NNRUWF8Xq95uOPPza//OUvTb9+/czOnTuNMXZdUwTLRfzud78zY8aMMfHx8eY73/lOp1+L66sWLlxokpOTTVxcnHG73ebee+81n3zySWh7R0eHWb16tUlKSjJOp9Pceuut5tChQzEc8eVTVlZmJHVZcnNzjTGRzc3//vc/8/DDD5vExEQzaNAgc/fdd5v6+voYvJued6H5amtrM7NnzzYjR440cXFxJi0tzeTm5naZi74yX+ebJ0nmj3/8Y2gfrq8vXWyuuLa+8pOf/CT0GTdy5Ejzgx/8IBQrxth1TTmMMaZ779kAAAB0L55hAQAA1iNYAACA9QgWAABgPYIFAABYj2ABAADWI1gAAID1CBYAAGA9ggUAAFiPYAEAANYjWAAAgPUIFgAAYD2CBQAAWO//Aw/SW7coO00DAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creiamo la varietà\n",
    "manifold = LevelSetManifold(g, dg, 1)\n",
    "# Test del parametro manifold\n",
    "\n",
    "theta = flatten(model.parameters()).to(device)\n",
    "theta = geoopt.ManifoldParameter(theta , manifold=manifold)\n",
    "\n",
    "print(\"Prima: \", \"g: \", g(theta).item(), \"dg: \", dg(theta))\n",
    "\n",
    "# Proiettiamo il parametro iniziale sulla varietà\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "# print(\"99\", \"Primo theta: \",  theta.data)\n",
    "print(\"############ Landing phase #############\")\n",
    "for i in range(10):\n",
    "    \n",
    "    theta.data = manifold.projx(theta.data)\n",
    "    if i%20 == 0:\n",
    "        print(i, \"g: \", g(theta).item(), \"dg: \", dg(theta))\n",
    "\n",
    "    if g(theta)< 1e-7:\n",
    "        print(\"Landed :)\")\n",
    "        break\n",
    "        \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "# Verifica che il parametro iniziale appartenga alla varietà\n",
    "#assert manifold._check_point_on_manifold(theta.data), \"Il punto iniziale non è sulla varietà\"\n",
    "\n",
    "# Definiamo una loss function: minimizziamo la norma quadrata\n",
    "def loss_fn(trainX, theta):\n",
    "    return torch.nn.CrossEntropyLoss()(model(trainX), trainy.long())  # Ad esempio, massimizzare la componente x[0]\n",
    "\n",
    "# Ottimizzatore Riemanniano\n",
    "optimizer = RiemannianSGD([theta], lr=0.01)\n",
    "\n",
    "# Ciclo di ottimizzazione\n",
    "g_during_train = []\n",
    "loss_history = []\n",
    "print(\"############## Training phase ################\")\n",
    "for epoch in range(300):\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(trainX, theta)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if epoch%10 == 0:\n",
    "        print(\"Epoch\",  epoch + 1, \n",
    "              \"Loss:\", loss.item(),\n",
    "#               \"theta:\", theta.data[1].item(),\n",
    "              \"g(theta):\", round(float(g(theta).data),8))\n",
    "    loss_history.append(loss.item())\n",
    "    g_during_train.append(g(theta).data)\n",
    "# plt.plot(g_during_train)\n",
    "plt.plot(loss_history)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "# Risultato finale\n",
    "print(\"Punto finale:\", theta)\n",
    "print(\"Appartiene alla varietà?\", manifold._check_point_on_manifold(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21b6ec87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ -4.8218,  -9.2161,  -4.3466,  -5.5885,  -1.9368,   2.8326,   8.4917,\n",
       "           4.5118,   1.2219, -10.1857]], device='cuda:0',\n",
       "       grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand((1,28*28)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f71132b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-5.5287, -9.4397, -2.2649, -3.4448, -1.1030,  4.9758,  8.5125,  3.5182,\n",
      "         2.2373, -8.3812], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ -4.2014,  -7.3325,  -4.5015,  -8.1811,   0.2742,   3.0746,  10.7341,\n",
      "          8.6203,   2.6262, -12.3201], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor([-4.2178, -8.6134, -1.7216, -3.8780, -2.5200,  4.1737,  8.4461,  2.8710,\n",
      "         1.6021, -8.8662], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ -4.8070,  -7.2062,  -6.1222,  -6.6201,   2.5847,   6.9334,  12.2857,\n",
      "          8.2458,   0.1926, -14.0597], device='cuda:0',\n",
      "       grad_fn=<SelectBackward0>)\n",
      "tensor(6.5977, device='cuda:0', grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "trainX_180 = rotate(img = trainX, angle = 180)\n",
    "trainX_270 = rotate(img = trainX, angle = 270)\n",
    "\n",
    "print(model(trainX)[0])\n",
    "print(model(trainX_90)[0])\n",
    "print(model(trainX_180)[0])\n",
    "print(model(trainX_270)[0])\n",
    "\n",
    "print((model(trainX)[0] - model(trainX_180)[0]).norm()**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c9099c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d73f822",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaf4ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a52993b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce48b64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e967910",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a07790d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (1804443423.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [11]\u001b[1;36m\u001b[0m\n\u001b[1;33m    model.parameters() = deflatten(thetas, model.get_shapes())\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "model.parameters() = deflatten(thetas, model.get_shapes())\n",
    "NN1 = model(trainX)\n",
    "NN2 = model(trainX_90)\n",
    "Delta_NN = NN1 - NN2\n",
    "norm = Delta_NN.norm()**2\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff204c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0c4e3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
