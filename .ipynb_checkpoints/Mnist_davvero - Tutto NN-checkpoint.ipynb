{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76c705a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import geoopt\n",
    "from geoopt.optim import RiemannianSGD, RiemannianAdam\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from torch.func import grad\n",
    "\n",
    "import torch\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from matplotlib import pyplot as plt\n",
    "from torchvision.transforms.functional import rotate\n",
    "from scipy.linalg import lstsq, null_space\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82510dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training.\n",
    "device = \"cuda\"\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60fafc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def G(d): # questa è  rot_mat\n",
    "    mat = np.zeros(d**4).reshape(d**2,d**2)\n",
    "    for j in range(d):\n",
    "        for i in range(d):\n",
    "            k = (i+1)*d-j\n",
    "            h = i+(j)*d+1\n",
    "\n",
    "            mat[h-1][k-1] = 1\n",
    "    return mat\n",
    "\n",
    "def W(output_dim, d = 4):\n",
    "    kernel = null_space((np.identity(d*d) -  G(d)).T).T\n",
    "    W = []\n",
    "    for j in range(output_dim):\n",
    "        vec = np.zeros(d**2)\n",
    "        for k in kernel:\n",
    "            vec = np.random.random()*k + vec\n",
    "        W.append(list(vec))\n",
    "    W = np.array(W)/len(kernel)\n",
    "    return np.array(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3bef129",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: X=torch.Size([10, 28, 28]), y=torch.Size([10])\n",
      "Test: X=(10000, 28, 28), y=(10000,)\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "(trainX, trainy), (testX, testy) = mnist.load_data()\n",
    "\n",
    "trainX = trainX[:10]\n",
    "trainy = trainy[:10]\n",
    "\n",
    "trainy = torch.Tensor(trainy).to(device)\n",
    "trainX = trainX / 256\n",
    "testX = testX / 256\n",
    "\n",
    "trainX = torch.Tensor(trainX).to(device)\n",
    "trainX_90 = rotate(img = trainX, angle = 90)\n",
    "\n",
    "# summarize loaded dataset\n",
    "print('Train: X=%s, y=%s' % (trainX.shape, trainy.shape))\n",
    "print('Test: X=%s, y=%s' % (testX.shape, testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb35c8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "\n",
    "class InvariantNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden, output):\n",
    "        super(InvariantNN, self).__init__()\n",
    "        \n",
    "#         self.softmax = nn.Softmax()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden = hidden\n",
    "        self.output = output\n",
    "    \n",
    "        self.flatten = nn.Flatten(start_dim=1)\n",
    "        self.l1 = nn.Linear(self.input_dim, self.hidden)\n",
    "        self.l2 = nn.Linear(self.hidden, self.hidden)\n",
    "        self.l3 = nn.Linear(self.hidden, self.output)\n",
    "        \n",
    "        self.leakyrelu = nn.LeakyReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        \n",
    "        self.acc_loss = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def get_shapes(self):\n",
    "        shapes = [(self.input_dim, self.hidden), \n",
    "                  (self.hidden,1),\n",
    "                  (self.hidden, self.hidden),\n",
    "                  (self.hidden,1),\n",
    "                  (self.hidden, self.output),\n",
    "                  (self.output,1)\n",
    "                 ]\n",
    "        return shapes\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.tanh(x)\n",
    "        x = self.l2(x)    \n",
    "        x = self.tanh(x)\n",
    "        x = self.l3(x)\n",
    "\n",
    "        return  x\n",
    "    \n",
    "model = InvariantNN(28*28, 64, 10).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e014bb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95306"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28*28*64 + 64 + 64*64 + 64 * 64*10 + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77d977aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(weights_list):\n",
    "    flatten_weights = []\n",
    "    for weight in weights_list:\n",
    "        flatten_weights.append(weight.flatten())\n",
    "        \n",
    "    return torch.concatenate(flatten_weights)\n",
    "\n",
    "def deflatten(weights_flat, shapes):\n",
    "    weigths_list = []\n",
    "    shape_counter = 0\n",
    "    for shape in shapes:\n",
    "        weight = torch.Tensor(weights_flat[shape_counter: shape_counter + np.prod(shape)])\n",
    "        shape_counter = shape_counter + np.prod(shape)\n",
    "        \n",
    "        weigths_list.append(weight.reshape(shape))\n",
    "            \n",
    "    return weigths_list\n",
    "\n",
    "# Funzione che definisce la varietà: sfera unitaria centrata in 0\n",
    "def g(thetas):\n",
    "    \n",
    "    W1, b1, W2, b2, W3, b3 = deflatten(thetas, model.get_shapes())\n",
    "    model.l1.weight.data = W1.T\n",
    "    model.l2.weight.data = W2.T\n",
    "    model.l3.weight.data = W3.T\n",
    "    model.l1.bias.data = b1.T\n",
    "    model.l2.bias.data = b2.T\n",
    "    model.l3.bias.data = b3.T\n",
    "    \n",
    "    \n",
    "    NN1 = model(trainX)\n",
    "    NN2 = model(trainX_90)\n",
    "    Delta_NN = NN1 - NN2\n",
    "    norm = Delta_NN.norm()**2\n",
    "    \n",
    "    # Zero grad\n",
    "    for param in model.parameters():\n",
    "        param.grad = torch.zeros(param.shape).to(device)\n",
    "        \n",
    "    # Compute gradient\n",
    "    norm.backward()\n",
    "    \n",
    "    return norm # sfera unitaria\n",
    "\n",
    "\n",
    "def dg(thetas):\n",
    "    _ = g(thetas)\n",
    "    def_grad = [param.grad for param in model.parameters()]\n",
    "    \n",
    "    \n",
    "    return flatten(def_grad)\n",
    "\n",
    "# # Gradiente di f\n",
    "# def dg(thetas):\n",
    "#     gradient = grad(g)(thetas)\n",
    "#     return gradient #+ 1e-5*(gradient.norm()==0)\n",
    "\n",
    "\n",
    "# Classe LevelSetManifold già implementata sopra\n",
    "class LevelSetManifold(geoopt.manifolds.Manifold):\n",
    "    \n",
    "    ndim = 1\n",
    "    name = \"Caste\"\n",
    "    \n",
    "    def __init__(self, f, df, lr_proj = 1):\n",
    "        super().__init__()\n",
    "        self.f = f\n",
    "        self.df = df\n",
    "        self.lr_proj = lr_proj\n",
    "\n",
    "    def _check_point_on_manifold(self, x, atol=1e-7, rtol=1e-7):\n",
    "        return torch.abs(self.f(x)) < atol\n",
    "\n",
    "    def _check_vector_on_tangent(self, x, u, atol=1e-7, rtol=1e-7):\n",
    "        grad_f = self.df(x)\n",
    "        return torch.abs(u @ grad_f).sum() < atol\n",
    "    \n",
    "    def projx(self,x):\n",
    "        if self._check_point_on_manifold(x):\n",
    "            return x\n",
    "        for r in range(100):\n",
    "            x = self.single_projx(x)\n",
    "            if r%50==0:\n",
    "                print(\"g: \", self.f(x))\n",
    "                print(\"dg: \", self.df(x).norm())\n",
    "            if r == 99:\n",
    "                print(f\"Retraction applied {r + 1} times\")\n",
    "            if self._check_point_on_manifold(x):\n",
    "                print(f\"Retraction applied {r + 1} times\")\n",
    "                break\n",
    "        return x\n",
    "    \n",
    "    def single_projx(self, x):\n",
    "        \"\"\"\n",
    "        Retraction\n",
    "        \"\"\"\n",
    "        grad_f = self.df(x)\n",
    "        f_val = self.f(x)\n",
    "        return x - 1*self.lr_proj*(f_val / grad_f.norm()**2 * grad_f)\n",
    "\n",
    "    def proju(self, x, u):\n",
    "        \"\"\"\n",
    "        Projected gradient\n",
    "        \"\"\"\n",
    "        grad_f = self.df(x)\n",
    "        return u - 1*(u @ grad_f) / grad_f.norm()**2 * grad_f\n",
    "\n",
    "    def inner(self, x, u, v=None):\n",
    "        if v is None:\n",
    "            v = u\n",
    "        return (u * v).sum()\n",
    "\n",
    "    def expmap(self, x, u):\n",
    "        return self.retr(x, u)\n",
    "\n",
    "    def egrad2rgrad(self, x, u):\n",
    "        return self.proju(x, u)\n",
    "\n",
    "    def retr(self, x, u):\n",
    "        x_new = x + u\n",
    "        return self.projx(x_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "560a1d00",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prima:  g:  46915772.0 dg:  tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "############ Landing phase #############\n",
      "g:  tensor(39043836., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(19927022., device='cuda:0')\n",
      "g:  tensor(3058468., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3314382.5000, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "0 g:  3755605.0 dg:  tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "g:  tensor(4665771., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(5525179.5000, device='cuda:0')\n",
      "g:  tensor(638567.1875, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(261838.6719, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(1241904.8750, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(496777.8750, device='cuda:0')\n",
      "g:  tensor(941268.0625, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(115042.8359, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(946526.8750, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(1201255., device='cuda:0')\n",
      "g:  tensor(5726090.5000, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(297399.3438, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(26818116., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(4748181., device='cuda:0')\n",
      "g:  tensor(36249712., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(22253520., device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(50164496., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(15240876., device='cuda:0')\n",
      "g:  tensor(54027676., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(73744488., device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(48444032., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(9103977., device='cuda:0')\n",
      "g:  tensor(62417128., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(58947484., device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(84776272., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(41583720., device='cuda:0')\n",
      "g:  tensor(95045592., device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(42217852., device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(1.2364e+08, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(99506816., device='cuda:0')\n",
      "g:  tensor(2.3231e+08, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(66880780., device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(3.4110e+08, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(47022608., device='cuda:0')\n",
      "g:  tensor(1.3033e+09, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(3.6660e+08, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(1.4442e+10, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(1.7695e+09, device='cuda:0')\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n",
      "Retraction applied 100 times\n",
      "g:  tensor(7.7718e+35, device='cuda:0', grad_fn=<PowBackward0>)\n",
      "dg:  tensor(inf, device='cuda:0')\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m############ Landing phase #############\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 16\u001b[0m     theta\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m \u001b[43mmanifold\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprojx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtheta\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m20\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     18\u001b[0m         \u001b[38;5;28mprint\u001b[39m(i, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg: \u001b[39m\u001b[38;5;124m\"\u001b[39m, g(theta)\u001b[38;5;241m.\u001b[39mitem(), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdg: \u001b[39m\u001b[38;5;124m\"\u001b[39m, dg(theta))\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mLevelSetManifold.projx\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m---> 82\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msingle_projx\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m r\u001b[38;5;241m%\u001b[39m\u001b[38;5;241m50\u001b[39m\u001b[38;5;241m==\u001b[39m\u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m     84\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mg: \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(x))\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mLevelSetManifold.single_projx\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msingle_projx\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[0;32m     94\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;124;03m    Retraction\u001b[39;00m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 98\u001b[0m     grad_f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     99\u001b[0m     f_val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf(x)\n\u001b[0;32m    100\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m10\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr_proj\u001b[38;5;241m*\u001b[39m(f_val \u001b[38;5;241m/\u001b[39m grad_f\u001b[38;5;241m.\u001b[39mnorm()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m grad_f)\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mdg\u001b[1;34m(thetas)\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdg\u001b[39m(thetas):\n\u001b[1;32m---> 47\u001b[0m     _ \u001b[38;5;241m=\u001b[39m \u001b[43mg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mthetas\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     48\u001b[0m     def_grad \u001b[38;5;241m=\u001b[39m [param\u001b[38;5;241m.\u001b[39mgrad \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters()]\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m flatten(def_grad)\n",
      "Input \u001b[1;32mIn [18]\u001b[0m, in \u001b[0;36mg\u001b[1;34m(thetas)\u001b[0m\n\u001b[0;32m     27\u001b[0m model\u001b[38;5;241m.\u001b[39ml2\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m b2\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m     28\u001b[0m model\u001b[38;5;241m.\u001b[39ml3\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata \u001b[38;5;241m=\u001b[39m b3\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m---> 31\u001b[0m NN1 \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m NN2 \u001b[38;5;241m=\u001b[39m model(trainX_90)\n\u001b[0;32m     33\u001b[0m Delta_NN \u001b[38;5;241m=\u001b[39m NN1 \u001b[38;5;241m-\u001b[39m NN2\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Input \u001b[1;32mIn [5]\u001b[0m, in \u001b[0;36mInvariantNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml1(x)\n\u001b[0;32m     38\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[1;32m---> 39\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m    \n\u001b[0;32m     40\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtanh(x)\n\u001b[0;32m     41\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39ml3(x)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\geo\\lib\\site-packages\\torch\\nn\\modules\\linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Creiamo la varietà\n",
    "manifold = LevelSetManifold(g, dg, 1)\n",
    "# Test del parametro manifold\n",
    "\n",
    "theta = flatten(model.parameters()).to(device)\n",
    "theta = geoopt.ManifoldParameter(theta , manifold=manifold)\n",
    "\n",
    "print(\"Prima: \", \"g: \", g(theta).item(), \"dg: \", dg(theta))\n",
    "\n",
    "# Proiettiamo il parametro iniziale sulla varietà\n",
    "print(\"\\n\\n\\n\\n\\n\")\n",
    "# print(\"99\", \"Primo theta: \",  theta.data)\n",
    "print(\"############ Landing phase #############\")\n",
    "for i in range(100):\n",
    "    \n",
    "    theta.data = manifold.projx(theta.data)\n",
    "    if i%20 == 0:\n",
    "        print(i, \"g: \", g(theta).item(), \"dg: \", dg(theta))\n",
    "\n",
    "    if g(theta)< 1e-7:\n",
    "        print(\"Landed :)\")\n",
    "        break\n",
    "        \n",
    "print(\"\\n\\n\")\n",
    "\n",
    "\n",
    "for param in model.parameters():\n",
    "    print(param)\n",
    "\n",
    "\n",
    "# # Verifica che il parametro iniziale appartenga alla varietà\n",
    "# assert manifold._check_point_on_manifold(theta.data), \"Il punto iniziale non è sulla varietà\"\n",
    "\n",
    "# # Definiamo una loss function: minimizziamo la norma quadrata\n",
    "# def loss_fn(trainX, theta):\n",
    "#     return torch.nn.CrossEntropyLoss()(model(trainX), trainy.long())  # Ad esempio, massimizzare la componente x[0]\n",
    "\n",
    "# # Ottimizzatore Riemanniano\n",
    "# optimizer = RiemannianSGD([theta], lr=0.01)\n",
    "\n",
    "# # Ciclo di ottimizzazione\n",
    "# g_during_train = []\n",
    "# loss_history = []\n",
    "# print(\"############## Training phase ################\")\n",
    "# for epoch in range(300):\n",
    "#     optimizer.zero_grad()\n",
    "#     loss = loss_fn(trainX, theta)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "#     if epoch%10 == 0:\n",
    "#         print(\"Epoch\",  epoch + 1, \n",
    "#               \"Loss:\", loss.item(),\n",
    "# #               \"theta:\", theta.data[1].item(),\n",
    "#               \"g(theta):\", round(float(g(theta).data),8))\n",
    "#     loss_history.append(loss.item())\n",
    "#     g_during_train.append(g(theta).data)\n",
    "# # plt.plot(g_during_train)\n",
    "# plt.plot(loss_history)\n",
    "# print(\"\\n\\n\")\n",
    "\n",
    "# # Risultato finale\n",
    "# print(\"Punto finale:\", theta)\n",
    "# print(\"Appartiene alla varietà?\", manifold._check_point_on_manifold(theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ede91b17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0156,  0.0270, -0.0675, -0.1485,  0.0009,  0.2047, -0.1855, -0.2172,\n",
       "          0.2070,  0.0085]], device='cuda:0', grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand((1,28*28)).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f63b961",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.0920, -0.1515,  0.0263, -0.0449,  0.0230, -0.0267,  0.0494, -0.2308,\n",
      "         0.0306, -0.0242], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0887, -0.2437,  0.2314,  0.0809,  0.0989,  0.2074,  0.0328,  0.0054,\n",
      "        -0.0752,  0.2148], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([ 0.0797, -0.1287,  0.1587, -0.0900,  0.0355, -0.0677,  0.2700, -0.0908,\n",
      "        -0.0872,  0.0877], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor([-0.0571, -0.1274,  0.2138,  0.0775,  0.1360,  0.1250, -0.0140, -0.1159,\n",
      "         0.0218,  0.2602], device='cuda:0', grad_fn=<SelectBackward0>)\n",
      "tensor(0.1168, device='cuda:0', grad_fn=<PowBackward0>)\n"
     ]
    }
   ],
   "source": [
    "trainX_180 = rotate(img = trainX, angle = 180)\n",
    "trainX_270 = rotate(img = trainX, angle = 270)\n",
    "\n",
    "print(model(trainX)[0])\n",
    "print(model(trainX_90)[0])\n",
    "print(model(trainX_180)[0])\n",
    "print(model(trainX_270)[0])\n",
    "\n",
    "print((model(trainX)[0] - model(trainX_180)[0]).norm()**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e057f58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c88e88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2685336c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f81719",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a9e205",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c028e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85e844be",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to function call (1804443423.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Input \u001b[1;32mIn [11]\u001b[1;36m\u001b[0m\n\u001b[1;33m    model.parameters() = deflatten(thetas, model.get_shapes())\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m cannot assign to function call\n"
     ]
    }
   ],
   "source": [
    "model.parameters() = deflatten(thetas, model.get_shapes())\n",
    "NN1 = model(trainX)\n",
    "NN2 = model(trainX_90)\n",
    "Delta_NN = NN1 - NN2\n",
    "norm = Delta_NN.norm()**2\n",
    "print(norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07630a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52531ee6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
